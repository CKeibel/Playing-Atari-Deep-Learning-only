{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMn53p6YR-pf"
   },
   "source": [
    "# playing Atari with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lgxvXMASR-py"
   },
   "outputs": [],
   "source": [
    "# choose game\n",
    "game = \"Pong-v0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA37Mc9dTo99"
   },
   "source": [
    "# generate Dataset by random play\n",
    "\n",
    "* saving only good sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRFkZvcjR-p0",
    "outputId": "3b2f9605-3a06-4a77-8ac3-4dba2f7e6a67",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "Dataset completed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "env = gym.make(game)\n",
    "x_data = [] # Bilder (States)\n",
    "y_data = [] # Label (Aktionen)\n",
    "\n",
    "DATASET_SIZE = 1500\n",
    "saved_episodes = 0\n",
    "\n",
    "# Datensatz generieren\n",
    "the_end = False\n",
    "while not the_end:\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    episode_obs = []\n",
    "    episode_acts = []\n",
    "  \n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        episode_obs.append(state)\n",
    "        episode_acts.append(action)\n",
    "        state, reward, done, info = env.step(action)\n",
    "    \n",
    "        if reward < 0:\n",
    "            episode_acts = []\n",
    "            episode_obs = []\n",
    "        elif reward > 0:\n",
    "            x_data += episode_obs\n",
    "            y_data += episode_acts\n",
    "            episode_obs = []\n",
    "            episode_acts = []\n",
    "            saved_episodes += 1\n",
    "            if saved_episodes % 100 == 0:\n",
    "                print(saved_episodes)\n",
    "            if saved_episodes+1 > DATASET_SIZE:\n",
    "                print(\"Dataset completed\")\n",
    "                the_end = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TTqB01eYUB6"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PdMRdMwMZYSv",
    "outputId": "cb66f955-2b59-4176-b438-69e349958bb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((116229, 210, 160, 3), (116229,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ww_OsqftZqAO",
    "outputId": "42b59ef2-fbe5-4119-8e95-e1c17d461ba7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9PFtrNLY5Sd"
   },
   "source": [
    "### resize images to 84x84 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uyIJN1MVbaEc"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def resize(img):\n",
    "    height = 84\n",
    "    width = 84\n",
    "    return cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "roOO6duzbySo"
   },
   "outputs": [],
   "source": [
    "resized_x_data = [resize(img) for img in x_data]\n",
    "resized_x_data = np.array(resized_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "UTbEwSSdaHDU",
    "outputId": "0498bd1e-a192-4233-bd95-26ce27a73773"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Resized')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "axs[0].imshow(x_data[0, :, :, :])\n",
    "axs[0].set_title(\"Original\", fontsize=\"15\")\n",
    "axs[1].imshow(resized_x_data[0, :, :, :])\n",
    "axs[1].set_title(\"Resized\", fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCrcMOZpeEru"
   },
   "source": [
    "### RGB to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jAwmi_HaeJdg"
   },
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = np.reshape(img, (img.shape[0], img.shape[1], 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Bf7I6ZIdf8t7"
   },
   "outputs": [],
   "source": [
    "gray_x_data = [grayscale(img) for img in resized_x_data]\n",
    "gray_x_data = np.array(gray_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "k6Di_4PAg-Ol",
    "outputId": "6c4f6002-173a-4bab-fa3b-88440b72df9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Grayscale')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(resized_x_data[0, :, :, :])\n",
    "axs[0].set_title(\"Resized\", fontsize=\"15\")\n",
    "axs[1].imshow(gray_x_data[0, :, :, 0], cmap=\"gray\")\n",
    "axs[1].set_title(\"Grayscale\", fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxC3qk02i7Fp"
   },
   "source": [
    "### Frame Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gj_qhnX1jDXm"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "def framestack(dataset):\n",
    "    data = []\n",
    "    frames = deque(maxlen=4)\n",
    "\n",
    "    # initialize first deque\n",
    "    for _ in range(4):\n",
    "        frames.append(dataset[0])\n",
    "    framestack = np.asarray(frames, dtype=np.float32)\n",
    "    framestack = np.moveaxis(framestack, 0, -1).reshape(84, 84, -1)\n",
    "\n",
    "    # create deques from dataset\n",
    "    for state in dataset:\n",
    "        frames.append(state)\n",
    "        framestack = np.asarray(frames, dtype=np.float32)\n",
    "        framestack = np.moveaxis(framestack, 0, -1).reshape(84, 84, -1)\n",
    "        data.append(framestack)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJKjcCDMpUTL",
    "outputId": "5c933575-4d49-4f95-aa2f-c945a8520cc4"
   },
   "outputs": [],
   "source": [
    "stack_data = framestack(gray_x_data) \n",
    "stack_data = np.array(stack_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "kNCHiv0jrXso",
    "outputId": "ff5164c2-af6f-4917-ea0f-0140b3dcd4f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd33273470>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(10,5))\n",
    "axs[0].imshow(stack_data[0+4, :, :, 0], cmap=\"gray\") # +4, because of 4 same initial frames\n",
    "axs[1].imshow(stack_data[1+4, :, :, 1], cmap=\"gray\")\n",
    "axs[2].imshow(stack_data[2+4, :, :, 2], cmap=\"gray\")\n",
    "axs[3].imshow(stack_data[3+4, :, :, 3], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1czVT38wzbHJ"
   },
   "source": [
    "### converting labels to categorical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7L2wBkTtzaZ_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y=y_data, num_classes=env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H1fJpNxwSPy"
   },
   "source": [
    "### shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rBI7d68iwRBn"
   },
   "outputs": [],
   "source": [
    "# create random indices\n",
    "idx = np.random.permutation(len(x_data))\n",
    "# x - resized grayscale input\n",
    "# x_stacked - resized grayscale input in framestacks\n",
    "# labels - actions in to_categorical\n",
    "x, x_stacked, labels = gray_x_data[idx], stack_data[idx], y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoWl4NPBR-p7"
   },
   "source": [
    "# create a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "YQYdMrat39p5"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_nn(input_shape, output_shape):\n",
    "    net_input = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=32, kernel_size=(8, 8), strides=(4, 4), padding=\"same\")(net_input)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dense(output_shape)(x)\n",
    "    net_output = Activation(\"softmax\")(x)\n",
    "\n",
    "    OPTIMIZER = Adam(lr=0.00005)\n",
    "\n",
    "    model = Model(inputs=net_input, outputs=net_output)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER, metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MwFT04i4tQg"
   },
   "source": [
    "# Train a model on resized-grayscale input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Q4GjusRR-p8",
    "outputId": "808691c7-f8f1-442a-e5ca-77cdbcf39cd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIfmFHv_5Q-1",
    "outputId": "ba7e6db4-d19b-4280-e6e6-87490e0017a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "3MUt_E1K4_zt"
   },
   "outputs": [],
   "source": [
    "model_1 = create_nn(x.shape[1:], labels.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "id": "n6d2qk_IR-p9",
    "outputId": "7a07eaf1-1cf2-459b-8cfb-2683c07af2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "116229/116229 [==============================] - 9s 80us/sample - loss: 1.9791 - categorical_accuracy: 0.1726\n",
      "Epoch 2/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.8264 - categorical_accuracy: 0.1699\n",
      "Epoch 3/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 1.8061 - categorical_accuracy: 0.1747\n",
      "Epoch 4/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.7996 - categorical_accuracy: 0.1743\n",
      "Epoch 5/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 1.7947 - categorical_accuracy: 0.1783\n",
      "Epoch 6/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 1.7917 - categorical_accuracy: 0.1812\n",
      "Epoch 7/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.7906 - categorical_accuracy: 0.1810\n",
      "Epoch 8/250\n",
      "116229/116229 [==============================] - 8s 73us/sample - loss: 1.7893 - categorical_accuracy: 0.1819\n",
      "Epoch 9/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 1.7883 - categorical_accuracy: 0.1846\n",
      "Epoch 10/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.7872 - categorical_accuracy: 0.1860\n",
      "Epoch 11/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.7865 - categorical_accuracy: 0.1889\n",
      "Epoch 12/250\n",
      "116229/116229 [==============================] - 9s 75us/sample - loss: 1.7856 - categorical_accuracy: 0.1903\n",
      "Epoch 13/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.7845 - categorical_accuracy: 0.1918\n",
      "Epoch 14/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 1.7825 - categorical_accuracy: 0.1968\n",
      "Epoch 15/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 1.7805 - categorical_accuracy: 0.2001\n",
      "Epoch 16/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 1.7780 - categorical_accuracy: 0.2043\n",
      "Epoch 17/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.7746 - categorical_accuracy: 0.2084\n",
      "Epoch 18/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 1.7710 - categorical_accuracy: 0.2131\n",
      "Epoch 19/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.7664 - categorical_accuracy: 0.2192\n",
      "Epoch 20/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 1.7605 - categorical_accuracy: 0.2259\n",
      "Epoch 21/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 1.7538 - categorical_accuracy: 0.2341\n",
      "Epoch 22/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 1.7461 - categorical_accuracy: 0.2416\n",
      "Epoch 23/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 1.7366 - categorical_accuracy: 0.2517\n",
      "Epoch 24/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 1.7262 - categorical_accuracy: 0.2611\n",
      "Epoch 25/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.7145 - categorical_accuracy: 0.2702\n",
      "Epoch 26/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 1.7010 - categorical_accuracy: 0.2815\n",
      "Epoch 27/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 1.6865 - categorical_accuracy: 0.2905\n",
      "Epoch 28/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.6703 - categorical_accuracy: 0.3033\n",
      "Epoch 29/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 1.6530 - categorical_accuracy: 0.3155\n",
      "Epoch 30/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 1.6346 - categorical_accuracy: 0.3252\n",
      "Epoch 31/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.6144 - categorical_accuracy: 0.3373\n",
      "Epoch 32/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 1.5942 - categorical_accuracy: 0.3505\n",
      "Epoch 33/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 1.5723 - categorical_accuracy: 0.3649\n",
      "Epoch 34/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 1.5493 - categorical_accuracy: 0.3757\n",
      "Epoch 35/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 1.5263 - categorical_accuracy: 0.3880\n",
      "Epoch 36/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 1.5016 - categorical_accuracy: 0.4014\n",
      "Epoch 37/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.4777 - categorical_accuracy: 0.4119\n",
      "Epoch 38/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.4526 - categorical_accuracy: 0.4244\n",
      "Epoch 39/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 1.4279 - categorical_accuracy: 0.4373\n",
      "Epoch 40/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 1.4027 - categorical_accuracy: 0.4495\n",
      "Epoch 41/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.3780 - categorical_accuracy: 0.4609\n",
      "Epoch 42/250\n",
      "116229/116229 [==============================] - 8s 73us/sample - loss: 1.3518 - categorical_accuracy: 0.4736\n",
      "Epoch 43/250\n",
      "116229/116229 [==============================] - 9s 75us/sample - loss: 1.3267 - categorical_accuracy: 0.4857\n",
      "Epoch 44/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 1.3033 - categorical_accuracy: 0.4959\n",
      "Epoch 45/250\n",
      "116229/116229 [==============================] - 9s 73us/sample - loss: 1.2777 - categorical_accuracy: 0.5063\n",
      "Epoch 46/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 1.2547 - categorical_accuracy: 0.5177\n",
      "Epoch 47/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.2304 - categorical_accuracy: 0.5283\n",
      "Epoch 48/250\n",
      "116229/116229 [==============================] - 9s 73us/sample - loss: 1.2070 - categorical_accuracy: 0.5392\n",
      "Epoch 49/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 1.1843 - categorical_accuracy: 0.5491\n",
      "Epoch 50/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 1.1625 - categorical_accuracy: 0.5571\n",
      "Epoch 51/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.1415 - categorical_accuracy: 0.5673\n",
      "Epoch 52/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 1.1187 - categorical_accuracy: 0.5756\n",
      "Epoch 53/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 1.0991 - categorical_accuracy: 0.5823\n",
      "Epoch 54/250\n",
      "116229/116229 [==============================] - 8s 73us/sample - loss: 1.0790 - categorical_accuracy: 0.5912\n",
      "Epoch 55/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 1.0606 - categorical_accuracy: 0.5992\n",
      "Epoch 56/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 1.0425 - categorical_accuracy: 0.6065\n",
      "Epoch 57/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 1.0230 - categorical_accuracy: 0.6146\n",
      "Epoch 58/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 1.0043 - categorical_accuracy: 0.6229\n",
      "Epoch 59/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.9862 - categorical_accuracy: 0.6280\n",
      "Epoch 60/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.9709 - categorical_accuracy: 0.6357\n",
      "Epoch 61/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.9552 - categorical_accuracy: 0.6419\n",
      "Epoch 62/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.9383 - categorical_accuracy: 0.6468\n",
      "Epoch 63/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.9247 - categorical_accuracy: 0.6536\n",
      "Epoch 64/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 0.9097 - categorical_accuracy: 0.6590\n",
      "Epoch 65/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.8942 - categorical_accuracy: 0.6659\n",
      "Epoch 66/250\n",
      "116229/116229 [==============================] - 8s 73us/sample - loss: 0.8814 - categorical_accuracy: 0.6713\n",
      "Epoch 67/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.8695 - categorical_accuracy: 0.6758\n",
      "Epoch 68/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.8551 - categorical_accuracy: 0.6806\n",
      "Epoch 69/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.8437 - categorical_accuracy: 0.6850\n",
      "Epoch 70/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.8335 - categorical_accuracy: 0.6880\n",
      "Epoch 71/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.8176 - categorical_accuracy: 0.6950\n",
      "Epoch 72/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.8079 - categorical_accuracy: 0.6973\n",
      "Epoch 73/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.7979 - categorical_accuracy: 0.7024\n",
      "Epoch 74/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.7848 - categorical_accuracy: 0.7067\n",
      "Epoch 75/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.7760 - categorical_accuracy: 0.7098\n",
      "Epoch 76/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.7654 - categorical_accuracy: 0.7138\n",
      "Epoch 77/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.7575 - categorical_accuracy: 0.7172\n",
      "Epoch 78/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.7463 - categorical_accuracy: 0.7211\n",
      "Epoch 79/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.7373 - categorical_accuracy: 0.7260\n",
      "Epoch 80/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.7298 - categorical_accuracy: 0.7272\n",
      "Epoch 81/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.7206 - categorical_accuracy: 0.7298\n",
      "Epoch 82/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.7116 - categorical_accuracy: 0.7336\n",
      "Epoch 83/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.7049 - categorical_accuracy: 0.7360\n",
      "Epoch 84/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.6967 - categorical_accuracy: 0.7388\n",
      "Epoch 85/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.6896 - categorical_accuracy: 0.7406\n",
      "Epoch 86/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.6803 - categorical_accuracy: 0.7462\n",
      "Epoch 87/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.6745 - categorical_accuracy: 0.7476\n",
      "Epoch 88/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.6676 - categorical_accuracy: 0.7488\n",
      "Epoch 89/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.6614 - categorical_accuracy: 0.7523\n",
      "Epoch 90/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.6546 - categorical_accuracy: 0.7550\n",
      "Epoch 91/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.6503 - categorical_accuracy: 0.7563\n",
      "Epoch 92/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.6434 - categorical_accuracy: 0.7580\n",
      "Epoch 93/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.6352 - categorical_accuracy: 0.7615\n",
      "Epoch 94/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.6301 - categorical_accuracy: 0.7637\n",
      "Epoch 95/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.6233 - categorical_accuracy: 0.7661\n",
      "Epoch 96/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.6179 - categorical_accuracy: 0.7680\n",
      "Epoch 97/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 0.6136 - categorical_accuracy: 0.7698\n",
      "Epoch 98/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.6052 - categorical_accuracy: 0.7725\n",
      "Epoch 99/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.6040 - categorical_accuracy: 0.7737\n",
      "Epoch 100/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.5957 - categorical_accuracy: 0.7767\n",
      "Epoch 101/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.5935 - categorical_accuracy: 0.7774\n",
      "Epoch 102/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.5879 - categorical_accuracy: 0.7801\n",
      "Epoch 103/250\n",
      "116229/116229 [==============================] - 9s 75us/sample - loss: 0.5830 - categorical_accuracy: 0.7809\n",
      "Epoch 104/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.5762 - categorical_accuracy: 0.7837\n",
      "Epoch 105/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.5728 - categorical_accuracy: 0.7847\n",
      "Epoch 106/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.5671 - categorical_accuracy: 0.7878\n",
      "Epoch 107/250\n",
      "116229/116229 [==============================] - 9s 75us/sample - loss: 0.5681 - categorical_accuracy: 0.7864\n",
      "Epoch 108/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.5588 - categorical_accuracy: 0.7907\n",
      "Epoch 109/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.5559 - categorical_accuracy: 0.7916\n",
      "Epoch 110/250\n",
      "116229/116229 [==============================] - 9s 73us/sample - loss: 0.5543 - categorical_accuracy: 0.7921\n",
      "Epoch 111/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.5477 - categorical_accuracy: 0.7941\n",
      "Epoch 112/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.5437 - categorical_accuracy: 0.7965\n",
      "Epoch 113/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.5410 - categorical_accuracy: 0.7965\n",
      "Epoch 114/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.5388 - categorical_accuracy: 0.7978\n",
      "Epoch 115/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.5353 - categorical_accuracy: 0.7986\n",
      "Epoch 116/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.5319 - categorical_accuracy: 0.8001\n",
      "Epoch 117/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.5254 - categorical_accuracy: 0.8012\n",
      "Epoch 118/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.5225 - categorical_accuracy: 0.8043\n",
      "Epoch 119/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.5226 - categorical_accuracy: 0.8041\n",
      "Epoch 120/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.5174 - categorical_accuracy: 0.8056\n",
      "Epoch 121/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.5138 - categorical_accuracy: 0.8072\n",
      "Epoch 122/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.5105 - categorical_accuracy: 0.8087\n",
      "Epoch 123/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.5081 - categorical_accuracy: 0.8088\n",
      "Epoch 124/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.5035 - categorical_accuracy: 0.8104\n",
      "Epoch 125/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.4997 - categorical_accuracy: 0.8126\n",
      "Epoch 126/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.4995 - categorical_accuracy: 0.8112\n",
      "Epoch 127/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.4948 - categorical_accuracy: 0.8133\n",
      "Epoch 128/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.4908 - categorical_accuracy: 0.8160\n",
      "Epoch 129/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.4896 - categorical_accuracy: 0.8164\n",
      "Epoch 130/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.4906 - categorical_accuracy: 0.8152\n",
      "Epoch 131/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 0.4837 - categorical_accuracy: 0.8184\n",
      "Epoch 132/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.4802 - categorical_accuracy: 0.8199\n",
      "Epoch 133/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.4824 - categorical_accuracy: 0.8197\n",
      "Epoch 134/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.4798 - categorical_accuracy: 0.8208\n",
      "Epoch 135/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.4733 - categorical_accuracy: 0.8233\n",
      "Epoch 136/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.4728 - categorical_accuracy: 0.8214\n",
      "Epoch 137/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.4709 - categorical_accuracy: 0.8229\n",
      "Epoch 138/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.4688 - categorical_accuracy: 0.8247\n",
      "Epoch 139/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.4670 - categorical_accuracy: 0.8242\n",
      "Epoch 140/250\n",
      "116229/116229 [==============================] - 9s 75us/sample - loss: 0.4644 - categorical_accuracy: 0.8265\n",
      "Epoch 141/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.4614 - categorical_accuracy: 0.8264\n",
      "Epoch 142/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.4599 - categorical_accuracy: 0.8277\n",
      "Epoch 143/250\n",
      "116229/116229 [==============================] - 9s 75us/sample - loss: 0.4583 - categorical_accuracy: 0.8290\n",
      "Epoch 144/250\n",
      "116229/116229 [==============================] - 8s 73us/sample - loss: 0.4544 - categorical_accuracy: 0.8296\n",
      "Epoch 145/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.4536 - categorical_accuracy: 0.8304\n",
      "Epoch 146/250\n",
      "116229/116229 [==============================] - 9s 75us/sample - loss: 0.4525 - categorical_accuracy: 0.8301\n",
      "Epoch 147/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.4519 - categorical_accuracy: 0.8317\n",
      "Epoch 148/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.4488 - categorical_accuracy: 0.8310\n",
      "Epoch 149/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.4446 - categorical_accuracy: 0.8334\n",
      "Epoch 150/250\n",
      "116229/116229 [==============================] - 8s 73us/sample - loss: 0.4432 - categorical_accuracy: 0.8337\n",
      "Epoch 151/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.4431 - categorical_accuracy: 0.8343\n",
      "Epoch 152/250\n",
      "116229/116229 [==============================] - 9s 75us/sample - loss: 0.4402 - categorical_accuracy: 0.8352\n",
      "Epoch 153/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.4378 - categorical_accuracy: 0.8360\n",
      "Epoch 154/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.4370 - categorical_accuracy: 0.8358\n",
      "Epoch 155/250\n",
      "116229/116229 [==============================] - 9s 75us/sample - loss: 0.4335 - categorical_accuracy: 0.8374\n",
      "Epoch 156/250\n",
      "116229/116229 [==============================] - 9s 73us/sample - loss: 0.4338 - categorical_accuracy: 0.8369\n",
      "Epoch 157/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.4319 - categorical_accuracy: 0.8384\n",
      "Epoch 158/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.4309 - categorical_accuracy: 0.8387\n",
      "Epoch 159/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.4289 - categorical_accuracy: 0.8394\n",
      "Epoch 160/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.4279 - categorical_accuracy: 0.8400\n",
      "Epoch 161/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.4265 - categorical_accuracy: 0.8406\n",
      "Epoch 162/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.4244 - categorical_accuracy: 0.8414\n",
      "Epoch 163/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.4232 - categorical_accuracy: 0.8421\n",
      "Epoch 164/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.4234 - categorical_accuracy: 0.8426\n",
      "Epoch 165/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.4218 - categorical_accuracy: 0.8421\n",
      "Epoch 166/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.4190 - categorical_accuracy: 0.8442\n",
      "Epoch 167/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.4168 - categorical_accuracy: 0.8439\n",
      "Epoch 168/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.4153 - categorical_accuracy: 0.8445\n",
      "Epoch 169/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.4184 - categorical_accuracy: 0.8439\n",
      "Epoch 170/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.4129 - categorical_accuracy: 0.8460\n",
      "Epoch 171/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 0.4120 - categorical_accuracy: 0.8460\n",
      "Epoch 172/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.4115 - categorical_accuracy: 0.8467\n",
      "Epoch 173/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.4095 - categorical_accuracy: 0.8473\n",
      "Epoch 174/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.4088 - categorical_accuracy: 0.8461\n",
      "Epoch 175/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.4106 - categorical_accuracy: 0.8470\n",
      "Epoch 176/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.4052 - categorical_accuracy: 0.8481\n",
      "Epoch 177/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.4058 - categorical_accuracy: 0.8484\n",
      "Epoch 178/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.4048 - categorical_accuracy: 0.8485\n",
      "Epoch 179/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.4018 - categorical_accuracy: 0.8496\n",
      "Epoch 180/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.4003 - categorical_accuracy: 0.8494\n",
      "Epoch 181/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.4021 - categorical_accuracy: 0.8496\n",
      "Epoch 182/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.3985 - categorical_accuracy: 0.8506\n",
      "Epoch 183/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 0.3986 - categorical_accuracy: 0.8519\n",
      "Epoch 184/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.3988 - categorical_accuracy: 0.8507\n",
      "Epoch 185/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.3969 - categorical_accuracy: 0.8521\n",
      "Epoch 186/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.3969 - categorical_accuracy: 0.8508\n",
      "Epoch 187/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.3954 - categorical_accuracy: 0.8519\n",
      "Epoch 188/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3927 - categorical_accuracy: 0.8527\n",
      "Epoch 189/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.3914 - categorical_accuracy: 0.8530\n",
      "Epoch 190/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.3936 - categorical_accuracy: 0.8532\n",
      "Epoch 191/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.3898 - categorical_accuracy: 0.8531\n",
      "Epoch 192/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.3935 - categorical_accuracy: 0.8533\n",
      "Epoch 193/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.3911 - categorical_accuracy: 0.8529\n",
      "Epoch 194/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3881 - categorical_accuracy: 0.8540\n",
      "Epoch 195/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.3875 - categorical_accuracy: 0.8548\n",
      "Epoch 196/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3858 - categorical_accuracy: 0.8564\n",
      "Epoch 197/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3857 - categorical_accuracy: 0.8563\n",
      "Epoch 198/250\n",
      "116229/116229 [==============================] - 9s 75us/sample - loss: 0.3833 - categorical_accuracy: 0.8564\n",
      "Epoch 199/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.3856 - categorical_accuracy: 0.8551\n",
      "Epoch 200/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.3834 - categorical_accuracy: 0.8566\n",
      "Epoch 201/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.3837 - categorical_accuracy: 0.8565\n",
      "Epoch 202/250\n",
      "116229/116229 [==============================] - 9s 73us/sample - loss: 0.3797 - categorical_accuracy: 0.8572\n",
      "Epoch 203/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3829 - categorical_accuracy: 0.8566\n",
      "Epoch 204/250\n",
      "116229/116229 [==============================] - 9s 73us/sample - loss: 0.3785 - categorical_accuracy: 0.8588\n",
      "Epoch 205/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.3791 - categorical_accuracy: 0.8580\n",
      "Epoch 206/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.3776 - categorical_accuracy: 0.8587\n",
      "Epoch 207/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.3773 - categorical_accuracy: 0.8587\n",
      "Epoch 208/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.3782 - categorical_accuracy: 0.8576\n",
      "Epoch 209/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.3748 - categorical_accuracy: 0.8593\n",
      "Epoch 210/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.3777 - categorical_accuracy: 0.8593\n",
      "Epoch 211/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.3744 - categorical_accuracy: 0.8599\n",
      "Epoch 212/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.3734 - categorical_accuracy: 0.8588\n",
      "Epoch 213/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3743 - categorical_accuracy: 0.8597\n",
      "Epoch 214/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.3735 - categorical_accuracy: 0.8603\n",
      "Epoch 215/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3725 - categorical_accuracy: 0.8596\n",
      "Epoch 216/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3697 - categorical_accuracy: 0.8602\n",
      "Epoch 217/250\n",
      "116229/116229 [==============================] - 9s 78us/sample - loss: 0.3725 - categorical_accuracy: 0.8605\n",
      "Epoch 218/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.3681 - categorical_accuracy: 0.8615\n",
      "Epoch 219/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3680 - categorical_accuracy: 0.8617\n",
      "Epoch 220/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.3670 - categorical_accuracy: 0.8616\n",
      "Epoch 221/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.3700 - categorical_accuracy: 0.8605\n",
      "Epoch 222/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3684 - categorical_accuracy: 0.8613\n",
      "Epoch 223/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 0.3683 - categorical_accuracy: 0.8615\n",
      "Epoch 224/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.3649 - categorical_accuracy: 0.8627\n",
      "Epoch 225/250\n",
      "116229/116229 [==============================] - 8s 69us/sample - loss: 0.3650 - categorical_accuracy: 0.8629\n",
      "Epoch 226/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 0.3655 - categorical_accuracy: 0.8624\n",
      "Epoch 227/250\n",
      "116229/116229 [==============================] - 8s 73us/sample - loss: 0.3639 - categorical_accuracy: 0.8644\n",
      "Epoch 228/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3629 - categorical_accuracy: 0.8635\n",
      "Epoch 229/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 0.3635 - categorical_accuracy: 0.8624\n",
      "Epoch 230/250\n",
      "116229/116229 [==============================] - 9s 73us/sample - loss: 0.3633 - categorical_accuracy: 0.8638\n",
      "Epoch 231/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3609 - categorical_accuracy: 0.8648\n",
      "Epoch 232/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 0.3612 - categorical_accuracy: 0.8640\n",
      "Epoch 233/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.3626 - categorical_accuracy: 0.8633\n",
      "Epoch 234/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3590 - categorical_accuracy: 0.8639\n",
      "Epoch 235/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.3585 - categorical_accuracy: 0.8649\n",
      "Epoch 236/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.3579 - categorical_accuracy: 0.8640\n",
      "Epoch 237/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.3590 - categorical_accuracy: 0.8642\n",
      "Epoch 238/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3574 - categorical_accuracy: 0.8645\n",
      "Epoch 239/250\n",
      "116229/116229 [==============================] - 9s 73us/sample - loss: 0.3560 - categorical_accuracy: 0.8646\n",
      "Epoch 240/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.3563 - categorical_accuracy: 0.8650\n",
      "Epoch 241/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3566 - categorical_accuracy: 0.8653\n",
      "Epoch 242/250\n",
      "116229/116229 [==============================] - 9s 77us/sample - loss: 0.3557 - categorical_accuracy: 0.8655\n",
      "Epoch 243/250\n",
      "116229/116229 [==============================] - 8s 71us/sample - loss: 0.3542 - categorical_accuracy: 0.8653\n",
      "Epoch 244/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3549 - categorical_accuracy: 0.8655\n",
      "Epoch 245/250\n",
      "116229/116229 [==============================] - 9s 76us/sample - loss: 0.3549 - categorical_accuracy: 0.8662\n",
      "Epoch 246/250\n",
      "116229/116229 [==============================] - 8s 72us/sample - loss: 0.3551 - categorical_accuracy: 0.8664\n",
      "Epoch 247/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3527 - categorical_accuracy: 0.8667\n",
      "Epoch 248/250\n",
      "116229/116229 [==============================] - 9s 74us/sample - loss: 0.3519 - categorical_accuracy: 0.8670\n",
      "Epoch 249/250\n",
      "116229/116229 [==============================] - 8s 73us/sample - loss: 0.3520 - categorical_accuracy: 0.8671\n",
      "Epoch 250/250\n",
      "116229/116229 [==============================] - 8s 70us/sample - loss: 0.3505 - categorical_accuracy: 0.8675\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 250\n",
    "\n",
    "result_1 = model_1.fit(\n",
    "    x,\n",
    "    labels,\n",
    "    batch_size=128,\n",
    "    epochs=EPOCHS, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save_weights(\"model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7ef6045d4198>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 541, in __del__\n",
      "    handle=self._handle, deleter=self._deleter)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 1175, in delete_iterator\n",
      "    \"DeleteIterator\", handle=handle, deleter=deleter, name=name)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 793, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 544, in create_op\n",
      "    inp = self.capture(inp)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 594, in capture\n",
      "    name = tensor.op.name\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1879, in name\n",
      "    return c_api.TF_OperationName(self._c_op)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xf6 in position 4: invalid start byte\n",
      "Exception ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7ef6045d4278>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 541, in __del__\n",
      "    handle=self._handle, deleter=self._deleter)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 1175, in delete_iterator\n",
      "    \"DeleteIterator\", handle=handle, deleter=deleter, name=name)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 793, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 544, in create_op\n",
      "    inp = self.capture(inp)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 594, in capture\n",
      "    name = tensor.op.name\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1879, in name\n",
      "    return c_api.TF_OperationName(self._c_op)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xf6 in position 4: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 \tReward: -15.0\n",
      "Episode: 2 \tReward: -18.0\n",
      "Episode: 3 \tReward: -16.0\n",
      "Episode: 4 \tReward: -19.0\n",
      "Episode: 5 \tReward: -17.0\n"
     ]
    }
   ],
   "source": [
    "for episode in range(5):\n",
    "    done = False\n",
    "    episode_reward = 0.0\n",
    "    state = env.reset()\n",
    "    state = resize(state)\n",
    "    state = grayscale(state)\n",
    "    state = np.reshape(state, (1, 84, 84, 1))\n",
    "    state = state.astype(\"float32\")\n",
    "    while not done:\n",
    "        action = np.argmax(model_1.predict(state))\n",
    "        state, reward, done, info = env.step(action)\n",
    "        state = resize(state)\n",
    "        state = grayscale(state)\n",
    "        state = np.reshape(state, (1, 84, 84, 1))\n",
    "        state = state.astype(\"float32\")\n",
    "        episode_reward += reward\n",
    "    print(\"Episode:\", episode+1, \"\\tReward:\", episode_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1TW5R-U7GPi"
   },
   "source": [
    "# Train a model on resized-grayscale-framestack input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_PC9GGe7PMu",
    "outputId": "aeff8a06-1c4d-47d8-9e83-bfbe8a8324ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QKcsZxqu7T2E",
    "outputId": "45ddfa2e-f1fe-43f2-dc1a-4cb2f879a076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "bsG39ZXA7Wbu"
   },
   "outputs": [],
   "source": [
    "model_2 = create_nn(x_stacked.shape[1:], labels.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "CDhw3fr47gJ7",
    "outputId": "9b192e99-e5f0-4c34-fce9-2297fee248cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "116229/116229 [==============================] - 53s 455us/sample - loss: 1.9934 - categorical_accuracy: 0.1681\n",
      "Epoch 2/30\n",
      "116229/116229 [==============================] - 52s 450us/sample - loss: 1.9052 - categorical_accuracy: 0.1704\n",
      "Epoch 3/30\n",
      "110624/116229 [===========================>..] - ETA: 2s - loss: 1.8797 - categorical_accuracy: 0.1712"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e27833abebb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     verbose=1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    119\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    120\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     return [_non_none_constant_value(out)\n\u001b[0;32m---> 84\u001b[0;31m             for out in distributed_function(input_fn)]\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    435\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 250\n",
    "\n",
    "result_2 = model_2.fit(\n",
    "    x_stacked,\n",
    "    labels,\n",
    "    batch_size=128,\n",
    "    epochs=EPOCHS, \n",
    "    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Playing_Atari_with_Deep-Learning_random_dataset.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
